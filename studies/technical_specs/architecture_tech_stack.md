<!-- @Study:ST-011 -->
# @Study:ST-019
# الهيكلية والمكدس التقني لمشروع "الموديل الخفي"
**Platform Architecture and Technology Stack**

**التاريخ:** 3 نوفمبر 2025
**المؤلف:** Manus AI
**الهدف:** تحديد المكدس التقني الأمثل الذي يوازن بين سرعة التطوير، قابلية التوسع، والكفاءة المطلوبة لمعالجة مهام الذكاء الاصطناعي الثقيلة.

## 1. الهيكلية العامة (General Architecture)

تعتمد الهيكلية المقترحة على مبدأ **فصل الاهتمامات (Separation of Concerns)**، حيث يتم فصل الواجهة الأمامية عن الواجهة الخلفية، وتتم معالجة مهام الذكاء الاصطناعي الثقيلة بشكل غير متزامن (Asynchronously) عبر نظام قائمة انتظار موثوق.

## 2. المكدس التقني الموصى به (Technology Stack)

تم اختيار المكدس التقني بناءً على الكفاءة والأداء العالي في بيئة الذكاء الاصطناعي.

| المكون | التقنية الموصى بها | التبرير التقني |
| :--- | :--- | :--- |
| **الواجهة الأمامية** | `React/Next.js` | يوفر أدوات قوية، ويدعم العرض من جانب الخادم (SSR) لتحسين الأداء وتجربة المستخدم. |
| **الواجهة الخلفية** | `Python` مع `FastAPI` | `Python` هي اللغة الأم لمعالجة الذكاء الاصطناعي (AI/ML)، و `FastAPI` يوفر أداءً عالياً جداً لاستقبال استدعاءات API الثقيلة لمعالجة الصور. |
| **قاعدة البيانات** | `PostgreSQL` | للموثوقية وتكامل البيانات، ويدعم هياكل بيانات معقدة مثل `JSONB`، ويدعم أمن مستوى الصف (RLS) لعزل العملاء (Multi-Tenancy). |
| **إدارة المهام** | `Celery` مع `Redis` | لمعالجة الصور بشكل غير متزامن (Asynchronous Task Management) لضمان الموثوقية وتجربة مستخدم سلسة. |
| **تخزين الملفات** | `Amazon S3` أو `Google Cloud Storage` | لتخزين الصور الأصلية والناتجة، مما يوفر قابلية توسع لا نهائية وفعالية في التكلفة. |

## 3. إدارة المهام غير المتزامنة (Asynchronous Task Management)

تُعد معالجة الصور بالذكاء الاصطناعي عملية غير متزامنة بطبيعتها. استخدام `Celery` مع `Redis` كقائمة انتظار أمر حاسم لضمان الموثوقية وتجربة مستخدم سلسة.

### 3.1. آلية العمل

1.  **الطلب:** يرفع المستخدم الصورة عبر الواجهة الأمامية.
2.  **الاستقبال:** تستقبل الواجهة الخلفية (`FastAPI`) الطلب وترسله كـ "مهمة" إلى قائمة انتظار `Celery`.
3.  **الاستجابة الفورية:** ترسل `FastAPI` استجابة فورية للمستخدم (HTTP 202 Accepted) مع رقم تعريف المهمة (`Job ID`)، دون إجباره على الانتظار.
4.  **المعالجة:** تقوم وحدات العمل (`Celery Workers`) بتنفيذ مهمة الذكاء الاصطناعي على خوادم GPU.
5.  **الإخطار:** عند الانتهاء، يتم تخزين الصورة الناتجة في `S3`، وتحديث حالة المهمة في `PostgreSQL`، وإخطار المستخدم بأن الصورة جاهزة.

### 3.2. فوائد الموثوقية التشغيلية

*   **تجربة مستخدم محسّنة:** لا يضطر المستخدم للانتظار على صفحة واحدة.
*   **قابلية التوسع:** يمكن إضافة المزيد من وحدات عمل `Celery` بسهولة لتلبية الطلب المتزايد.
*   **الموثوقية:** يضمن `Celery` إمكانية إعادة محاولة المهام الفاشلة تلقائياً في حال وجود أخطاء مؤقتة في الموارد أو الاتصال.

## 4. متطلبات البنية التحتية للذكاء الاصطناعي

يتطلب تشغيل نماذج الانتشار عالية الدقة (مثل SDXL) ووحدات IGR المخصصة وحدات معالجة رسوميات متخصصة.

| المطلب | التوصية | التبرير |
| :--- | :--- | :--- |
| **وحدات معالجة الرسوميات (GPU)** | `NVIDIA A100` أو `H100` | هي المعيار الصناعي لعمليات الاستدلال (Inference) والتدريب الدقيق (Fine-Tuning) لنماذج الذكاء الاصطناعي الكبيرة، وتوفر أفضل أداء مقابل التكلفة. |
| **التوسع التلقائي (Auto-Scaling)** | نظام توسع تلقائي مرتبط بطول قائمة انتظار `Celery`. | يضمن الكفاءة المالية، حيث يتم تخصيص الموارد باهظة الثمن (GPU) فقط عند الضرورة لمعالجة المهام المعلقة. |
| **بيئة موحدة** | `Docker/Containerization` | لضمان بيئة تشغيل موثوقة ومتسقة لجميع مكونات الذكاء الاصطناعي، مما يسهل عملية النشر والإدارة. |
